{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "# paths\n",
    "train_annotations_json = \"annotations.json\"\n",
    "val_annotations_json = \"annotations.json\"\n",
    "test_annotations_json = \"annotations.json\"\n",
    "path_split = \".\\\\CustomImages\\\\\" # folder with sets of train, val and test\n",
    "folder_train_split = \"train\"\n",
    "folder_val_split = \"val\"\n",
    "folder_test_split = \"test\"\n",
    "path_train_folder_split = os.path.join(path_split, folder_train_split)\n",
    "path_val_folder_split = os.path.join(path_split, folder_val_split)\n",
    "path_test_folder_split = os.path.join(path_split, folder_test_split)\n",
    "folder_yolo_train = \"labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate_coco_dataset(coco_annotation_path, images_folder_path):\n",
    "    \"\"\"\n",
    "    Validates a COCO dataset to check if the dimensions, IDs, and naming conventions are correct.\n",
    "\n",
    "    Parameters:\n",
    "    coco_annotation_path (str): Path to the COCO annotations JSON file.\n",
    "    images_folder_path (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the dataset is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    # Load the COCO annotations\n",
    "    with open(coco_annotation_path, 'r') as file:\n",
    "        coco_data = json.load(file)\n",
    "\n",
    "    # Create a set to store unique image IDs\n",
    "    image_ids = set()\n",
    "\n",
    "    # Validate images\n",
    "    for image_info in coco_data['images']:\n",
    "        image_id = image_info['id']\n",
    "        file_name = image_info['file_name']\n",
    "        width = image_info['width']\n",
    "        height = image_info['height']\n",
    "\n",
    "        # Check if image ID is unique\n",
    "        if image_id in image_ids:\n",
    "            print(f\"Duplicate image ID found: {image_id}\")\n",
    "            return False\n",
    "        image_ids.add(image_id)\n",
    "\n",
    "        # Check if the image file exists\n",
    "        image_path = os.path.join(images_folder_path, file_name)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image file not found: {file_name}\")\n",
    "            return False\n",
    "\n",
    "        # Check if the image dimensions match\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.width != width or img.height != height:\n",
    "                print(f\"Image dimensions do not match for {file_name}: \"\n",
    "                      f\"expected ({width}, {height}), got ({img.width}, {img.height})\")\n",
    "                return False\n",
    "\n",
    "    # Validate annotations\n",
    "    for annotation in coco_data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        if image_id not in image_ids:\n",
    "            print(f\"Annotation references non-existent image ID: {image_id}\")\n",
    "            return False\n",
    "\n",
    "    print(\"COCO dataset validation completed successfully.\")\n",
    "    return True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that annotation for training is correct\n",
      "COCO dataset validation completed successfully.\n",
      "True\n",
      "Check that annotation for validation is correct\n",
      "COCO dataset validation completed successfully.\n",
      "True\n",
      "Check that annotation for test is correct\n",
      "COCO dataset validation completed successfully.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"Check that annotation for training is correct\")\n",
    "print(validate_coco_dataset(os.path.join(path_train_folder_split,train_annotations_json), path_train_folder_split))\n",
    "print(\"Check that annotation for validation is correct\")\n",
    "print(validate_coco_dataset(os.path.join(path_val_folder_split,val_annotations_json), path_val_folder_split))\n",
    "print(\"Check that annotation for test is correct\")\n",
    "print(validate_coco_dataset(os.path.join(path_test_folder_split,test_annotations_json), path_test_folder_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_to_yolo_segmentation(coco_json_path, output_dir):\n",
    "    \"\"\"\n",
    "    Converts COCO segmentation annotations to YOLO format.\n",
    "\n",
    "    Args:\n",
    "    coco_json_path (str): Path to the COCO annotations JSON file.\n",
    "    output_dir (str): Path to the folder to save YOLO annotations.\n",
    "    \"\"\"\n",
    "    # Load COCO JSON\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Create a directory for YOLO annotations\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Create a mapping from COCO category IDs to YOLO class IDs (1-9 to 0-8)\n",
    "    category_mapping = {category['id']: category['id'] - 1 for category in coco_data['categories']}\n",
    "\n",
    "    # Iterate over each image in the COCO dataset\n",
    "    for image_info in coco_data['images']:\n",
    "        image_id = image_info['id']\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "        image_filename = image_info['file_name']\n",
    "\n",
    "        # Prepare the YOLO annotation filename\n",
    "        yolo_annotation_filename = os.path.splitext(image_filename)[0] + \".txt\"  # separate from .jpg\n",
    "        yolo_annotation_path = os.path.join(output_dir, yolo_annotation_filename)\n",
    "\n",
    "        # Open the YOLO annotation file for writing\n",
    "        with open(yolo_annotation_path, 'w') as yolo_file:\n",
    "            # Iterate over each annotation\n",
    "            for annotation in coco_data['annotations']:\n",
    "                if annotation['image_id'] == image_id:\n",
    "                    category_id = annotation['category_id']\n",
    "                    segmentation = annotation['segmentation']\n",
    "\n",
    "                    # Check if the annotation has polygon segmentation\n",
    "                    if isinstance(segmentation, list):\n",
    "                        for polygon in segmentation:\n",
    "                            # Normalize the coordinates by the dimensions of the image\n",
    "                            normalized_polygon = [(x / image_width, y / image_height) for x, y in zip(polygon[0::2], polygon[1::2])] \n",
    "                             # x: even indices, y: odd indices\n",
    "\n",
    "                            # Flatten the normalized coordinates\n",
    "                            normalized_polygon_str = ' '.join([f\"{x} {y}\" for x, y in normalized_polygon])\n",
    "\n",
    "                            # Get the YOLO class ID\n",
    "                            yolo_class_id = category_mapping[category_id]\n",
    "\n",
    "                            # Write the annotation in YOLO format\n",
    "                            yolo_file.write(f\"{yolo_class_id} {normalized_polygon_str}\\n\")\n",
    "\n",
    "    print(\"Conversion completed successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "convert_coco_to_yolo_segmentation(os.path.join(path_train_folder_split, train_annotations_json), os.path.join(path_train_folder_split, folder_yolo_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml_file(file_path, train_path, val_path, nc, names):\n",
    "    \"\"\"\n",
    "    Create yaml for yolo.\n",
    "\n",
    "        Args:\n",
    "            file_path: path of the yaml\n",
    "            train_path: path of the train set\n",
    "            val_path: path of the val set\n",
    "            nc: number of categories\n",
    "            names: names of the categories\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'train': train_path,\n",
    "        'val': val_path,\n",
    "        'nc': nc,\n",
    "        'names': names\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_train_folder_split, train_annotations_json), 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "names = [class_name['name'] for class_name in coco_data[\"categories\"]]\n",
    "\n",
    "# Specify the paths and information\n",
    "train_path = 'CustomImages/train/images'\n",
    "val_path = 'CustomImages//val/images'\n",
    "\n",
    "names = ['cat', 'dog']\n",
    "nc = len(names)\n",
    "file_path = 'data.yaml'\n",
    "\n",
    "# Create the YAML file\n",
    "create_yaml_file(file_path, train_path, val_path, nc, names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(path_train_folder_split, train_annotations_json), 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "names_categories = [class_name['name'] for class_name in coco_data[\"categories\"]]\n",
    "len(names_categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
