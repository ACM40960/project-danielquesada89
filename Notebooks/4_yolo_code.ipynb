{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#5fa8d3\"> Yolo model\n",
    "\n",
    "\n",
    "## <font color=\"#62b6cb\"> Table of Content <a name=\"ToC\"></a>\n",
    "0. [Libraries Importation, Parameters & Funtions Definition](#id0)<br>\n",
    "1. [Preparation of the data](#id1)<br>\n",
    "    1.1 [Copy Images to Yolo Folder](#id11)<br>\n",
    "    1.2 [Obtain the labels for YOLO](#id12)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#62b6cb\"> 0. Libraries Importation, Parameters & Funtions Definition <a name=\"id0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosas que poner en el config\n",
    "'./Notebooks/data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T15:40:57.002183Z",
     "start_time": "2024-07-25T15:40:56.937474Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import yaml # for importing a yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed directory to: /home/sagemaker-user/project-danielteresa\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "last_folder = os.path.basename(current_directory)\n",
    "    \n",
    "if last_folder != \"project-danielteresa\":\n",
    "    while last_folder != \"project-danielteresa\":\n",
    "        parent_directory = os.path.dirname(current_directory)\n",
    "        last_folder = os.path.basename(parent_directory)\n",
    "\n",
    "        os.chdir(parent_directory)\n",
    "        print(f\"Changed directory to: {parent_directory}\")\n",
    "else:\n",
    "    print(\"Already in the project root directory.\")\n",
    "\n",
    "# our modules\n",
    "from src.mymodule import * # for importing our functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables set from YAML file:\n",
      "seed: 123\n",
      "color1: #62b6cb\n",
      "color2: #fb8500\n",
      "color3: #023047\n",
      "color4: #FFB703\n",
      "path_annotations: ./Data\n",
      "path_train: ./Data/train/original\n",
      "path_train_train: ./Data/train/train\n",
      "path_train_aug: ./Data/train/train_aug\n",
      "path_train_val: ./Data/train/val\n",
      "path_test: ./Data/test\n",
      "path_yolo: ./Data/Yoloimages/\n",
      "kaggle_train_annotations: annotations_train.json\n",
      "train_annotations_name_temp: annotations_train_temp.json\n",
      "train_annotations_name: annotations_train_updated.json\n",
      "aug_train_annotations_name: annotations_train_updated_aug.json\n",
      "val_annotations_name: annotations_val_updated.json\n",
      "kaggle_test_annotations: annotations_test.json\n",
      "test_annotations_name_temp: annotations_test_temp.json\n",
      "test_annotations_name: annotations_test_updated.json\n",
      "weights_yolo_path: Models/yolo_weights\n",
      "runs_path: Models/runs\n"
     ]
    }
   ],
   "source": [
    "# Load the YAML file\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Function to set variables globally and store their names\n",
    "def set_variables(config, prefix='', var_dict={}):\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            set_variables(value, prefix + key + '_', var_dict)\n",
    "        else:\n",
    "            globals()[prefix + key] = value\n",
    "            var_dict[prefix + key] = value\n",
    "    return var_dict\n",
    "\n",
    "# Set variables globally and get a dictionary of the set variables\n",
    "set_vars = set_variables(config)\n",
    "\n",
    "# Print all the variables that were set\n",
    "print(\"Variables set from YAML file:\")\n",
    "for var_name, var_value in set_vars.items():\n",
    "    print(f\"{var_name}: {var_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#62b6cb\"> 1. Preparation of data <a name=\"id1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#62b6cb\"> 1.1 Copy Images to Yolo Folder  <a name=\"id11\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders have been cleaned and files have been copied successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the folders if they don't exist\n",
    "directories = [\n",
    "    os.path.join(path_yolo, \"train/images\"),\n",
    "    os.path.join(path_yolo, \"train/labels\"),\n",
    "    os.path.join(path_yolo, \"val/images\"),\n",
    "    os.path.join(path_yolo, \"val/labels\"),\n",
    "    os.path.join(path_yolo, \"test/images\"),\n",
    "    os.path.join(path_yolo, \"test/labels\")\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Remove everything that exists in the folders\n",
    "for directory in [    os.path.join(path_yolo, \"train/images\"),\n",
    "                      os.path.join(path_yolo, \"train/labels\"),\n",
    "                      os.path.join(path_yolo, \"val/images\"),\n",
    "                      os.path.join(path_yolo, \"val/labels\"),\n",
    "                      os.path.join(path_yolo, \"test/images\"),\n",
    "                      os.path.join(path_yolo, \"test/labels\")]:\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove the directory and its contents\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "# Copy images from train augmented to Yolo train folder\n",
    "shutil.copytree(path_train_aug, os.path.join(path_yolo, \"train/images\"), dirs_exist_ok=True)\n",
    "shutil.copytree(path_train_val, os.path.join(path_yolo, \"val/images\"), dirs_exist_ok=True)\n",
    "shutil.copytree(path_test, os.path.join(path_yolo, \"test/images\"), dirs_exist_ok=True)\n",
    "\n",
    "print(\"Folders have been cleaned and files have been copied successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the annotations and id of the coco jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that annotation for training is correct\n",
      "True\n",
      "Check that annotation for validation is correct\n",
      "True\n",
      "Check that annotation for test is correct\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"Check that annotation for training is correct\")\n",
    "print(validate_coco_dataset(os.path.join(path_annotations,aug_train_annotations_name), os.path.join(path_yolo,\"train/images\")))\n",
    "\n",
    "print(\"Check that annotation for validation is correct\")\n",
    "print(validate_coco_dataset(os.path.join(path_annotations,val_annotations_name), os.path.join(path_yolo,\"val/images\")))\n",
    "\n",
    "print(\"Check that annotation for test is correct\")\n",
    "print(validate_coco_dataset(os.path.join(path_annotations,test_annotations_name), os.path.join(path_yolo,\"test/images\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the points of the polygons are out of the range of the width and the height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the points of the polygons are out of the range of the images\n",
    "\n",
    "# train\n",
    "process_coco_annotations(os.path.join(path_annotations,aug_train_annotations_name),\n",
    "                          os.path.join(path_annotations,aug_train_annotations_name))\n",
    "\n",
    "# val\n",
    "process_coco_annotations(os.path.join(os.path.join(path_annotations,val_annotations_name)), \n",
    "                         os.path.join(os.path.join(path_annotations,val_annotations_name)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#62b6cb\"> 1.2 Obtain the labels for YOLO  <a name=\"id12\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the yolo txt for each images from the coco data annotations using the conver_coco from ultralytics. The annotations json to convert should be in a folder with that json in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/sagemaker-user/project-danielteresa/Data/Yoloimages/train/annotations_train_updated_aug.json: 100%|██████████| 46485/46485 [00:22<00:00, 2031.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /home/sagemaker-user/project-danielteresa/Data/Yoloimages/aux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed auxiliary directory ./Data/Yoloimages/aux\n",
      "Yolo labels saved in ./Data/Yoloimages/train/labels\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/sagemaker-user/project-danielteresa/Data/Yoloimages/val/annotations_val_updated.json: 100%|██████████| 2324/2324 [00:00<00:00, 11728.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /home/sagemaker-user/project-danielteresa/Data/Yoloimages/aux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed auxiliary directory ./Data/Yoloimages/aux\n",
      "Yolo labels saved in ./Data/Yoloimages/val/labels\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/sagemaker-user/project-danielteresa/Data/Yoloimages/test/annotations_test_updated.json: 100%|██████████| 2324/2324 [00:00<00:00, 12081.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /home/sagemaker-user/project-danielteresa/Data/Yoloimages/aux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed auxiliary directory ./Data/Yoloimages/aux\n",
      "Yolo labels saved in ./Data/Yoloimages/test/labels\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the yolo labels\n",
    "# train\n",
    "convert_coco_to_yolo_segmentation(path_annotations, aug_train_annotations_name, path_yolo, 'train')\n",
    "# val\n",
    "convert_coco_to_yolo_segmentation(path_annotations, val_annotations_name, path_yolo, 'val')\n",
    "# test\n",
    "convert_coco_to_yolo_segmentation(path_annotations, test_annotations_name, path_yolo, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the nº of elememts in the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in './Data/Yoloimages//train/labels': 46485\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "directory_path = path_yolo+'/train/labels'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Count the number of files\n",
    "file_count = len([file for file in files if os.path.isfile(os.path.join(directory_path, file))])\n",
    "\n",
    "print(f\"Number of files in '{directory_path}': {file_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a subset of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Set up\n",
    "train_folder = './Data/Yoloimages/train'\n",
    "val_folder = './Data/Yoloimages/val'\n",
    "\n",
    "destination_train_folder = './Data/Yoloimages/train_prueba'\n",
    "destination_val_folder = './Data/Yoloimages/val_prueba'\n",
    "\n",
    "# Seleccionar 20 imágenes de cada carpeta\n",
    "select_images(train_folder, destination_train_folder, 2000, 'images', 'labels')\n",
    "select_images(val_folder, destination_val_folder, 2000, 'images', 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yaml file is created for the yolo code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_annotations,val_annotations_name), 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "names = [class_name['name'] for class_name in coco_data[\"categories\"]]\n",
    "\n",
    "# Specify the paths and information\n",
    "actual_path = os.getcwd()\n",
    "train_path = os.path.join(actual_path, 'Data/Yoloimages/train_prueba/images')\n",
    "val_path = os.path.join(actual_path, 'Data/Yoloimages/val_prueba/images')\n",
    "\n",
    "names_categories = [class_name['name'] for class_name in coco_data[\"categories\"]]\n",
    "nc = len(names)\n",
    "file_path = './Notebooks/data.yaml'\n",
    "\n",
    "# Create the YAML file\n",
    "create_yaml_file(file_path, train_path, val_path, nc, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model or uploaded if it was already trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m-seg.pt to 'Models/yolo_weights/yolov8m-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52.4M/52.4M [00:00<00:00, 427MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.70 available 😃 Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.69 🚀 Python-3.10.14 torch-2.0.0.post104 CPU (Intel Xeon Platinum 8488C)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=Models/yolo_weights/yolov8m-seg.pt, data=./Notebooks/data.yaml, epochs=10, time=None, patience=100, batch=100, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=Models/runs, name=train, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Models/runs/train\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5164235  ultralytics.nn.modules.head.Segment          [9, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27,244,859 parameters, 27,244,843 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir Models/runs/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/sagemaker-user/project-danielteresa/Data/Yoloimages/train_prueba/labels.cache... 1999 images, 0 backgrounds, 1 corrupt: 100%|██████████| 2000/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/sagemaker-user/project-danielteresa/Data/Yoloimages/train_prueba/images/13032020_144742image419520.jpg: ignoring corrupt image/label: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/sagemaker-user/project-danielteresa/Data/Yoloimages/val_prueba/labels.cache... 1996 images, 0 backgrounds, 4 corrupt: 100%|██████████| 2000/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/sagemaker-user/project-danielteresa/Data/Yoloimages/val_prueba/images/02012020_082351image833616.jpg: ignoring corrupt image/label: image file is truncated (21 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/sagemaker-user/project-danielteresa/Data/Yoloimages/val_prueba/images/13032020_144737image20659.jpg: ignoring corrupt image/label: image file is truncated (0 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/sagemaker-user/project-danielteresa/Data/Yoloimages/val_prueba/images/25032020_091214image992948.jpg: ignoring corrupt image/label: broken data stream when reading image file\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /home/sagemaker-user/project-danielteresa/Data/Yoloimages/val_prueba/images/28042020_081842image605326.jpg: ignoring corrupt image/label: image file is truncated (0 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Models/runs/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.00078125), 96 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mModels/runs/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      2.048      4.513      4.405       2.14        241        640:  50%|█████     | 10/20 [10:42<10:36, 63.66s/it]"
     ]
    }
   ],
   "source": [
    "# Path to save/load the model\n",
    "model_path = \"./Models/yolo_model.pkl\"\n",
    "\n",
    "# Fit the GLM with Gamma family and log link if it is not saved\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading existing model...\")\n",
    "    yolo_model = joblib.load(model_path)\n",
    "else:\n",
    "    print(\"Training new model...\")\n",
    "    try:\n",
    "        if not os.path.exists(weights_yolo_path):\n",
    "            os.makedirs(weights_yolo_path)\n",
    "        # Initialize the YOLO model with the specified weights\n",
    "        yolo_model = YOLO(os.path.join(weights_yolo_path, \"yolov8m-seg.pt\"))\n",
    "        \n",
    "        # Train the YOLO model\n",
    "        yolo_model.train(data=\"./Notebooks/data.yaml\", \n",
    "                         batch=100,\n",
    "                         epochs=10, \n",
    "                         optimizer='Adam', \n",
    "                         task='segment',\n",
    "                         project=runs_path)\n",
    "        # Save the model\n",
    "        joblib.dump(yolo_model, model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error fitting the model:\", e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs\t100\t\n",
    "# patience\t100\n",
    "# batch\t16\tBatch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "# imgsz\t640\t\n",
    "# lr0\t0.01\tInitial learning rate (i.e. SGD=1E-2, Adam=1E-3) . Adjusting this value is crucial for the optimization process, influencing how rapidly model weights are updated.\n",
    "# weight_decay\t\n",
    "# dropout\n",
    "\n",
    "# USAR ADAM AUIDA A MAS RAPIDA CONVERGENCIA\n",
    "\n",
    "# verbose =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'lr0': [0.001, 0.01],  # Initial learning rate\n",
    "}\n",
    "\n",
    "# Tune the model\n",
    "model.tune(space=space, data='./Notebooks/data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=C:\\Users\\teres\\OneDrive\\Documentos\\UCD\\Summer\\project-danielteresa\\runs\\segment\\tune9'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/10 with hyperparameters: {'lr0': 0.01}\n"
     ]
    }
   ],
   "source": [
    "model.train(data=\"data.yaml\", epochs=100, optimizer='Adam', task='segment')\n",
    "\n",
    "# Path to save/load the model\n",
    "model_path = \"../Models/yolo_model.pkl\"\n",
    "\n",
    "# Fit the GLM with Gamma family and log link if it is not saved\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading existing model...\")\n",
    "    yolo_model = joblib.load(model_path)\n",
    "else:\n",
    "    print(\"Training new model...\")\n",
    "    try:\n",
    "        yolo_model = model.train(data=\"data.yaml\", epochs=100, optimizer='Adam', task='segment')\n",
    "        gb_model.fit(X_train, y_train)\n",
    "        # Save the model\n",
    "        joblib.dump(gb_model, model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error fitting the model:\", e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (8.2.69)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (4.10.0.82)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (0.18.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\teres\\onedrive\\documentos\\ucd\\summer\\project-danielteresa\\yolo_env\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 660.6 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.8 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.8 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.4/1.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.2\n"
     ]
    }
   ],
   "source": [
    "! python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\teres\\OneDrive\\Documentos\\UCD\\Summer\\project-danielteresa\\03bda226ad62553c0c73.jpg: 480x640 300 met_scratchs, 501.6ms\n",
      "Speed: 5.4ms preprocess, 501.6ms inference, 145.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(\"03bda226ad62553c0c73.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Masks object with attributes:\n",
       "\n",
       "data: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
       "orig_shape: (960, 1280)\n",
       "shape: torch.Size([132, 480, 640])\n",
       "xy: [array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32)]\n",
       "xyn: [array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32), array([], shape=(0, 2), dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\teres\\OneDrive\\Documentos\\UCD\\Summer\\project-danielteresa\\03bda226ad62553c0c73.jpg: 480x640 132 met_scratchs, 412.3ms\n",
      "Speed: 0.0ms preprocess, 412.3ms inference, 58.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Realizar predicciones\n",
    "results = model.predict(\"03bda226ad62553c0c73.jpg\", conf=0.9, iou=0.7)\n",
    "\n",
    "# Visualizar resultados\n",
    "for result in results:\n",
    "    img = result.plot(show=True, labels=True, masks=True, boxes=True)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
